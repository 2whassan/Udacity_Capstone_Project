{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder\\\n",
    "        .config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\")\\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0,saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    "        .enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "\n",
    "- This project deals with data absorbed from three differenct resources.\n",
    "- Fact and dimension tables are consructed to save the extracted data and peform the analysis.\n",
    "- The analysis is related to immigration to the US interms of monthly average temperature in each city, city demographics and seasonality of immigrants.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- The gathered data comes from 3 different places:\n",
    "1. __I94 Immigration Data__: This data comes from the US National Tourism and Trade Office. This data exists already here.\n",
    "2. __World Temperature Data__: This dataset came from Kaggle. You can read more about it [here](https://www.kaggle.com/datasets/berkeleyearth/climate-change-earth-surface-temperature-data).\n",
    "3. __U.S. City Demographic Data__: This data comes from OpenSoft. You can read more about it [here](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "i94_files = glob.glob(\"../../data/18-83510-I94-Data-2016/*.sas7bdat\")\n",
    "i94_file = \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    "i94_immig_df = spark.read.format(\"com.github.saurfang.sas.spark\").load(i94_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "temperature_file = \"../../data2/GlobalLandTemperaturesByCity.csv\"\n",
    "temperature_df = spark.read.format(\"csv\").option(\"delimiter\", \",\").option(\"header\", \"true\").load(temperature_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read demographics data\n",
    "demog_file = \"us-cities-demographics.csv\"\n",
    "demog_df = spark.read.format(\"csv\").option(\"delimiter\", \";\").option(\"header\", \"true\").load(demog_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigration dataset (exploring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20555.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247104e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1953.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247140e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NJ</td>\n",
       "      <td>20558.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247161e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247080e+10</td>\n",
       "      <td>00602</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>20562.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AZ</td>\n",
       "      <td>9.247849e+10</td>\n",
       "      <td>00608</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "5   18.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MI   \n",
       "6   19.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "7   20.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NJ   \n",
       "8   21.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "9   22.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      NY   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "5  20555.0   ...        None        M   1959.0  09302016   None   None   \n",
       "6  20558.0   ...        None        M   1953.0  09302016   None   None   \n",
       "7  20558.0   ...        None        M   1959.0  09302016   None   None   \n",
       "8  20553.0   ...        None        M   1970.0  09302016   None   None   \n",
       "9  20562.0   ...        None        M   1968.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "5      AZ  9.247104e+10  00602       B1  \n",
       "6      AZ  9.247140e+10  00602       B2  \n",
       "7      AZ  9.247161e+10  00602       B2  \n",
       "8      AZ  9.247080e+10  00602       B2  \n",
       "9      AZ  9.247849e+10  00608       B1  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data \n",
    "i94_immig_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659\n"
     ]
    }
   ],
   "source": [
    "# Create a list of valid ports\n",
    "i94_sas_label_descriptions_fname = \"I94_SAS_Labels_Descriptions.SAS\"\n",
    "with open(i94_sas_label_descriptions_fname) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports[results.group(1)] = results.group(2)\n",
    "print(len(valid_ports))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create a list of valid states\n",
    "valid_states = demog_df.toPandas()[\"State Code\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MD' 'MA' 'AL' 'CA' 'NJ' 'IL' 'AZ' 'MO' 'NC' 'PA' 'KS' 'FL' 'TX' 'VA' 'NV'\n",
      " 'CO' 'MI' 'CT' 'MN' 'UT' 'AR' 'TN' 'OK' 'WA' 'NY' 'GA' 'NE' 'KY' 'SC' 'LA'\n",
      " 'NM' 'IA' 'RI' 'PR' 'DC' 'WI' 'OR' 'NH' 'ND' 'DE' 'OH' 'ID' 'IN' 'AK' 'MS'\n",
      " 'HI' 'SD' 'ME' 'MT']\n"
     ]
    }
   ],
   "source": [
    "print(valid_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def convert_datetime(x):\n",
    "    \"\"\"\n",
    "    To convert SAS date to PySpark date \n",
    "    \"\"\"\n",
    "    if x:\n",
    "        return (datetime(1960, 1, 1).date() + timedelta(x)).isoformat()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def validate_state(x): \n",
    "    \"\"\"\n",
    "    To validate state\n",
    "    \"\"\"\n",
    "    if x in valid_states:\n",
    "        return x\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration dataset (cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>city_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>visa_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>168.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>WAS</td>\n",
       "      <td>DC</td>\n",
       "      <td>34.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>383.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>MIA</td>\n",
       "      <td>FL</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>TOR</td>\n",
       "      <td>TX</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>930.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NEW</td>\n",
       "      <td>NY</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1229.0</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>NYC</td>\n",
       "      <td>CT</td>\n",
       "      <td>32.0</td>\n",
       "      <td>M</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id        date city_code state_code   age gender  visa_type  count\n",
       "0   168.0  2016-04-01       WAS         DC  34.0      M        2.0    1.0\n",
       "1   383.0  2016-04-01       MIA         FL  40.0      M        2.0    1.0\n",
       "2   608.0  2016-04-01       TOR         TX  45.0      M        1.0    1.0\n",
       "3   930.0  2016-04-01       NEW         NY  49.0      F        2.0    1.0\n",
       "4  1229.0  2016-04-01       NYC         CT  32.0      M        1.0    1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove missing values\n",
    "cleaned_i94_df = i94_immig_df.dropna(how=\"any\", subset=[\"i94port\", \"i94addr\", \"gender\"])\n",
    "\n",
    "# Extract valid states \n",
    "cleaned_i94_df = cleaned_i94_df.withColumn(\"i94addr\", validate_state(cleaned_i94_df.i94addr))\n",
    "\n",
    "# Convert arrival_date (SAS format) to PySpark format\n",
    "cleaned_i94_df = cleaned_i94_df.withColumn(\"arrdate\", convert_datetime(cleaned_i94_df.arrdate))\n",
    "\n",
    "# Keeping on 'US' related immigration data\n",
    "cleaned_i94_df = cleaned_i94_df.filter(cleaned_i94_df.i94addr != 'other')\n",
    "\n",
    "staging_i94_df = cleaned_i94_df.select(col(\"cicid\").alias(\"id\"), \n",
    "                                       col(\"arrdate\").alias(\"date\"),\n",
    "                                       col(\"i94port\").alias(\"city_code\"),\n",
    "                                       col(\"i94addr\").alias(\"state_code\"),\n",
    "                                       col(\"i94bir\").alias(\"age\"),\n",
    "                                       col(\"gender\").alias(\"gender\"),\n",
    "                                       col(\"i94visa\").alias(\"visa_type\"),\n",
    "                                       \"count\").drop_duplicates()\n",
    "\n",
    "staging_i94_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature dataset (exploring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.7879999999999985</td>\n",
       "      <td>3.6239999999999997</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.2830000000000001</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.050999999999998</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt  AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01               6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01                None                          None  Århus   \n",
       "2  1744-01-01                None                          None  Århus   \n",
       "3  1744-02-01                None                          None  Århus   \n",
       "4  1744-03-01                None                          None  Århus   \n",
       "5  1744-04-01  5.7879999999999985            3.6239999999999997  Århus   \n",
       "6  1744-05-01              10.644            1.2830000000000001  Århus   \n",
       "7  1744-06-01  14.050999999999998                         1.347  Århus   \n",
       "8  1744-07-01              16.082                         1.396  Århus   \n",
       "9  1744-08-01                None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "temperature_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "@udf(StringType())\n",
    "def city_to_port(city):\n",
    "    \"\"\"\n",
    "    To map city full name to city port abbreviation\n",
    "    \"\"\"\n",
    "    for key in valid_ports:\n",
    "        if city.lower() in valid_ports[key].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Temperature dataset (cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>city_code</th>\n",
       "      <th>avg_temperature</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>COL</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>85.21W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>DAB</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>83.24W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>ONT</td>\n",
       "      <td>6.800000</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>116.76W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>POM</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>45.81N</td>\n",
       "      <td>123.46W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>PRO</td>\n",
       "      <td>14.300000</td>\n",
       "      <td>42.59N</td>\n",
       "      <td>72.00W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>TUL</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>36.17N</td>\n",
       "      <td>95.47W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>BAL</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>76.99W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>HSV</td>\n",
       "      <td>23.100000</td>\n",
       "      <td>34.56N</td>\n",
       "      <td>85.62W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>9</td>\n",
       "      <td>RNO</td>\n",
       "      <td>19.200001</td>\n",
       "      <td>39.38N</td>\n",
       "      <td>120.69W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>SLC</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>40.99N</td>\n",
       "      <td>112.90W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month city_code  avg_temperature     lat     long\n",
       "0  2013      4       COL        16.900000  32.95N   85.21W\n",
       "1  2013      1       DAB         0.500000  39.38N   83.24W\n",
       "2  2013      1       ONT         6.800000  34.56N  116.76W\n",
       "3  2013      2       POM         5.800000  45.81N  123.46W\n",
       "4  2013      5       PRO        14.300000  42.59N   72.00W\n",
       "5  2013      2       TUL         5.000000  36.17N   95.47W\n",
       "6  2013      1       BAL         1.800000  39.38N   76.99W\n",
       "7  2013      9       HSV        23.100000  34.56N   85.62W\n",
       "8  2013      9       RNO        19.200001  39.38N  120.69W\n",
       "9  2013      3       SLC         6.000000  40.99N  112.90W"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use only temperatures from 'United States'\n",
    "# Map full name to city port\n",
    "# Remove invalid ports\n",
    "cleaned_temp_df = temperature_df.filter(temperature_df[\"Country\"] == \"United States\") \\\n",
    "    .withColumn(\"year\", year(temperature_df['dt'])) \\\n",
    "    .withColumn(\"month\", month(temperature_df[\"dt\"])) \\\n",
    "    .withColumn(\"i94port\", city_to_port(temperature_df[\"City\"])) \\\n",
    "    .withColumn(\"AverageTemperature\", col(\"AverageTemperature\").cast(\"float\")) \\\n",
    "    .dropna(how='any', subset=[\"i94port\"])\n",
    "\n",
    "# Use only temperatures from 2013 (the latest year in the dataset)\n",
    "cleaned_temp_df = cleaned_temp_df.filter(cleaned_temp_df[\"year\"] == 2013)\n",
    "\n",
    "staging_temp_df = cleaned_temp_df.select(col(\"year\"), col(\"month\"), col(\"i94port\").alias(\"city_code\"),\n",
    "                                         round(col(\"AverageTemperature\"), 1).alias(\"avg_temperature\"),\n",
    "                                         col(\"Latitude\").alias(\"lat\"), col(\"Longitude\").alias(\"long\")).drop_duplicates()\n",
    "\n",
    "staging_temp_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographics dataset (exploring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601</td>\n",
       "      <td>41862</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562</td>\n",
       "      <td>30908</td>\n",
       "      <td>2.6</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129</td>\n",
       "      <td>49500</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147</td>\n",
       "      <td>32935</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040</td>\n",
       "      <td>46799</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819</td>\n",
       "      <td>8229</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127</td>\n",
       "      <td>87105</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821</td>\n",
       "      <td>33878</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040</td>\n",
       "      <td>143873</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829</td>\n",
       "      <td>86253</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56229</td>\n",
       "      <td>62432</td>\n",
       "      <td>118661</td>\n",
       "      <td>6634</td>\n",
       "      <td>7517</td>\n",
       "      <td>2.4</td>\n",
       "      <td>IL</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>1343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Avondale</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>29.1</td>\n",
       "      <td>38712</td>\n",
       "      <td>41971</td>\n",
       "      <td>80683</td>\n",
       "      <td>4815</td>\n",
       "      <td>8355</td>\n",
       "      <td>3.18</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>11592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Covina</td>\n",
       "      <td>California</td>\n",
       "      <td>39.8</td>\n",
       "      <td>51629</td>\n",
       "      <td>56860</td>\n",
       "      <td>108489</td>\n",
       "      <td>3800</td>\n",
       "      <td>37038</td>\n",
       "      <td>3.56</td>\n",
       "      <td>CA</td>\n",
       "      <td>Asian</td>\n",
       "      <td>32716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>O'Fallon</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>36.0</td>\n",
       "      <td>41762</td>\n",
       "      <td>43270</td>\n",
       "      <td>85032</td>\n",
       "      <td>5783</td>\n",
       "      <td>3269</td>\n",
       "      <td>2.77</td>\n",
       "      <td>MO</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>High Point</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>35.5</td>\n",
       "      <td>51751</td>\n",
       "      <td>58077</td>\n",
       "      <td>109828</td>\n",
       "      <td>5204</td>\n",
       "      <td>16315</td>\n",
       "      <td>2.65</td>\n",
       "      <td>NC</td>\n",
       "      <td>Asian</td>\n",
       "      <td>11060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City           State Median Age Male Population  \\\n",
       "0     Silver Spring        Maryland       33.8           40601   \n",
       "1            Quincy   Massachusetts       41.0           44129   \n",
       "2            Hoover         Alabama       38.5           38040   \n",
       "3  Rancho Cucamonga      California       34.5           88127   \n",
       "4            Newark      New Jersey       34.6          138040   \n",
       "5            Peoria        Illinois       33.1           56229   \n",
       "6          Avondale         Arizona       29.1           38712   \n",
       "7       West Covina      California       39.8           51629   \n",
       "8          O'Fallon        Missouri       36.0           41762   \n",
       "9        High Point  North Carolina       35.5           51751   \n",
       "\n",
       "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
       "0             41862            82463               1562        30908   \n",
       "1             49500            93629               4147        32935   \n",
       "2             46799            84839               4819         8229   \n",
       "3             87105           175232               5821        33878   \n",
       "4            143873           281913               5829        86253   \n",
       "5             62432           118661               6634         7517   \n",
       "6             41971            80683               4815         8355   \n",
       "7             56860           108489               3800        37038   \n",
       "8             43270            85032               5783         3269   \n",
       "9             58077           109828               5204        16315   \n",
       "\n",
       "  Average Household Size State Code                               Race  Count  \n",
       "0                    2.6         MD                 Hispanic or Latino  25924  \n",
       "1                   2.39         MA                              White  58723  \n",
       "2                   2.58         AL                              Asian   4759  \n",
       "3                   3.18         CA          Black or African-American  24437  \n",
       "4                   2.73         NJ                              White  76402  \n",
       "5                    2.4         IL  American Indian and Alaska Native   1343  \n",
       "6                   3.18         AZ          Black or African-American  11592  \n",
       "7                   3.56         CA                              Asian  32716  \n",
       "8                   2.77         MO                 Hispanic or Latino   2583  \n",
       "9                   2.65         NC                              Asian  11060  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "demog_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Demographics dataset (cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Calculate percentages of numeric columns and create new ones\n",
    "cleaned_demo_df = demog_df.withColumn(\"median_age\", demog_df['Median Age']) \\\n",
    "    .withColumn(\"pct_male_pop\", (demog_df['Male Population'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_female_pop\", (demog_df['Female Population'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_veterans\", (demog_df['Number of Veterans'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_foreign_born\", (demog_df['Foreign-born'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"pct_race\", (demog_df['Count'] / demog_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"city_code\", city_to_port(demog_df[\"City\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "cleaned_demo_df = cleaned_demo_df.select(col(\"City\").alias(\"city_name\"), col(\"State Code\").alias(\"state_code\"), \n",
    "                         \"median_age\", \"pct_male_pop\", \"pct_female_pop\",\"pct_veterans\", \n",
    "                         \"pct_foreign_born\", col(\"Total Population\").alias(\"total_pop\"), \n",
    "                         col(\"Race\").alias(\"race\"), \"pct_race\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Pivot the race column\n",
    "pivot_demo_df = cleaned_demo_df.groupBy(\"city_name\", \"state_code\", \"median_age\", \"pct_male_pop\",\n",
    "                                        \"pct_female_pop\",\"pct_veterans\", \"pct_foreign_born\", \"total_pop\").pivot(\"Race\").avg(\"pct_race\")\n",
    "\n",
    "pivot_demo_df = pivot_demo_df.withColumn(\"city_code\", city_to_port(pivot_demo_df[\"city_name\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "staging_demo_df = pivot_demo_df.select(\"city_code\", \"state_code\", \"city_name\", \"median_age\",\n",
    "                                    round(col(\"pct_male_pop\"), 1).alias(\"pct_male_pop\"),\n",
    "                                    round(col(\"pct_female_pop\"), 1).alias(\"pct_female_pop\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_veterans\"),\n",
    "                                    round(col(\"pct_veterans\"), 1).alias(\"pct_foreign_born\"),\n",
    "                                    round(col(\"American Indian and Alaska Native\"), 1).alias(\"pct_native_american\"),\n",
    "                                    round(col(\"Asian\"), 1).alias(\"pct_asian\"),\n",
    "                                    round(col(\"Black or African-American\"), 1).alias(\"pct_black\"),\n",
    "                                    round(col(\"Hispanic or Latino\"), 1).alias(\"pct_hispanic_or_latino\"),\n",
    "                                    round(col(\"White\"), 1).alias(\"pct_white\"), \"total_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_code</th>\n",
       "      <th>state_code</th>\n",
       "      <th>city_name</th>\n",
       "      <th>median_age</th>\n",
       "      <th>pct_male_pop</th>\n",
       "      <th>pct_female_pop</th>\n",
       "      <th>pct_veterans</th>\n",
       "      <th>pct_foreign_born</th>\n",
       "      <th>pct_native_american</th>\n",
       "      <th>pct_asian</th>\n",
       "      <th>pct_black</th>\n",
       "      <th>pct_hispanic_or_latino</th>\n",
       "      <th>pct_white</th>\n",
       "      <th>total_pop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TUC</td>\n",
       "      <td>AZ</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>33.6</td>\n",
       "      <td>49.8</td>\n",
       "      <td>50.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.4</td>\n",
       "      <td>43.5</td>\n",
       "      <td>76.1</td>\n",
       "      <td>531674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCA</td>\n",
       "      <td>TX</td>\n",
       "      <td>Allen</td>\n",
       "      <td>37.2</td>\n",
       "      <td>52.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>71.2</td>\n",
       "      <td>98138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CRP</td>\n",
       "      <td>TX</td>\n",
       "      <td>Corpus Christi</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.5</td>\n",
       "      <td>50.5</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>61.9</td>\n",
       "      <td>90.3</td>\n",
       "      <td>324082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FMY</td>\n",
       "      <td>FL</td>\n",
       "      <td>Fort Myers</td>\n",
       "      <td>37.3</td>\n",
       "      <td>49.8</td>\n",
       "      <td>50.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>24.1</td>\n",
       "      <td>67.8</td>\n",
       "      <td>74015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ORL</td>\n",
       "      <td>FL</td>\n",
       "      <td>Orlando</td>\n",
       "      <td>33.1</td>\n",
       "      <td>48.3</td>\n",
       "      <td>51.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.1</td>\n",
       "      <td>270917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOS</td>\n",
       "      <td>CA</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>50.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>10.2</td>\n",
       "      <td>48.8</td>\n",
       "      <td>54.8</td>\n",
       "      <td>3971896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRO</td>\n",
       "      <td>RI</td>\n",
       "      <td>Providence</td>\n",
       "      <td>29.9</td>\n",
       "      <td>49.7</td>\n",
       "      <td>50.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>17.1</td>\n",
       "      <td>43.5</td>\n",
       "      <td>54.6</td>\n",
       "      <td>179204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CID</td>\n",
       "      <td>IA</td>\n",
       "      <td>Cedar Rapids</td>\n",
       "      <td>36.2</td>\n",
       "      <td>48.4</td>\n",
       "      <td>51.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>89.6</td>\n",
       "      <td>130405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SPI</td>\n",
       "      <td>IL</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>38.8</td>\n",
       "      <td>47.2</td>\n",
       "      <td>52.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>21.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>77.2</td>\n",
       "      <td>117809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>POM</td>\n",
       "      <td>OR</td>\n",
       "      <td>Portland</td>\n",
       "      <td>36.7</td>\n",
       "      <td>49.6</td>\n",
       "      <td>50.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>82.9</td>\n",
       "      <td>632187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  city_code state_code       city_name median_age  pct_male_pop  \\\n",
       "0       TUC         AZ          Tucson       33.6          49.8   \n",
       "1       MCA         TX           Allen       37.2          52.3   \n",
       "2       CRP         TX  Corpus Christi       35.0          49.5   \n",
       "3       FMY         FL      Fort Myers       37.3          49.8   \n",
       "4       ORL         FL         Orlando       33.1          48.3   \n",
       "5       LOS         CA     Los Angeles       35.0          49.3   \n",
       "6       PRO         RI      Providence       29.9          49.7   \n",
       "7       CID         IA    Cedar Rapids       36.2          48.4   \n",
       "8       SPI         IL     Springfield       38.8          47.2   \n",
       "9       POM         OR        Portland       36.7          49.6   \n",
       "\n",
       "   pct_female_pop  pct_veterans  pct_foreign_born  pct_native_american  \\\n",
       "0            50.2           7.2               7.2                  4.6   \n",
       "1            47.7           3.6               3.6                  0.2   \n",
       "2            50.5           7.7               7.7                  0.9   \n",
       "3            50.2           5.8               5.8                  NaN   \n",
       "4            51.7           4.7               4.7                  0.9   \n",
       "5            50.7           2.2               2.2                  1.6   \n",
       "6            50.3           2.8               2.8                  2.3   \n",
       "7            51.6           6.0               6.0                  1.0   \n",
       "8            52.8           6.4               6.4                  1.4   \n",
       "9            50.4           4.7               4.7                  2.4   \n",
       "\n",
       "   pct_asian  pct_black  pct_hispanic_or_latino  pct_white total_pop  \n",
       "0        4.6        6.4                    43.5       76.1    531674  \n",
       "1       16.1       13.4                    10.8       71.2     98138  \n",
       "2        2.8        4.6                    61.9       90.3    324082  \n",
       "3        4.8       23.4                    24.1       67.8     74015  \n",
       "4        4.1       25.1                    33.0       66.1    270917  \n",
       "5       12.9       10.2                    48.8       54.8   3971896  \n",
       "6        7.5       17.1                    43.5       54.6    179204  \n",
       "7        4.1        9.1                     4.1       89.6    130405  \n",
       "8        3.3       21.5                     2.3       77.2    117809  \n",
       "9       10.2        7.3                     9.7       82.9    632187  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "staging_demo_df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "- We chose star schema for data modeling for simplicity by constructing staging, fact ,and dimension tables.\n",
    "\n",
    "### Staging tables\n",
    "1. __staging_i94_df__ >>>\n",
    "('id', 'date', 'city_code', 'state_code', 'age', 'gender', 'visa_type', 'count')\n",
    "2. __staging_temp_df__ >>>\n",
    "('year', 'month', 'city_code', 'city_name', 'avg_temperature', 'lat', 'long')\n",
    "3. __staging_demo_df__ >>>\n",
    "('city_code', 'state_code', 'city_name', 'median_age', 'pct_male_pop', 'pct_female_pop', 'pct_veterans', 'pct_foreign_born', 'pct_native_american',  'pct_asian', 'pct_black', 'pct_hispanic_or_latino', 'pct_white', 'total_pop')\n",
    "\n",
    "### Fact table\n",
    "1. __immigration_df__ >>>\n",
    "('id', 'state_code', 'city_code', 'date', 'count')\n",
    "\n",
    "### Dimension tables\n",
    "1. __immigrant_df__ >>>\n",
    "('id', 'gender', 'age', 'visa_type')\n",
    "2. __city_df__ >>>\n",
    "('city_code', 'state_code', 'city_name', 'median_age', 'pct_male_pop', 'pct_female_pop', 'pct_veterans', 'pct_foreign_born', 'pct_native_american', 'pct_asian', 'pct_black', 'pct_hispanic_or_latino', 'pct_white', 'total_pop', 'lat', 'long')\n",
    "3. __monthly_city_temp_df__ >>>\n",
    "('city_code', 'year', 'month', 'avg_temperature')\n",
    "4. __time_df__ >>>\n",
    "('date', 'dayofweek', 'weekofyear', 'month')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "1. Clean data (nulls, data types, duplicates, etc)\n",
    "2. Load staging tables.\n",
    "3. Create dimension tables.\n",
    "4. Create fact table immigration_df with information on immigration count, mapping id in immigrant_df, city_code in city_df and monthly_city_temp_df and date in time_df ensuring data integrity.\n",
    "6. Save processed tables in parquet for downstream query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create immigrant dimension table\n",
    "immigrant_df = staging_i94_df.select(\"id\", \"gender\", \"age\", \"visa_type\")\n",
    "immigrant_df = immigrant_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create city dimension table\n",
    "city_df = staging_demo_df.join(staging_temp_df, \"city_code\") \\\n",
    "    .select(\"city_code\", \"state_code\", \"city_name\", \"median_age\", \"pct_male_pop\", \"pct_female_pop\", \"pct_veterans\",\n",
    "           \"pct_foreign_born\", \"pct_native_american\", \"pct_asian\", \"pct_black\",\n",
    "           \"pct_hispanic_or_latino\", \"pct_white\", \"total_pop\", \"lat\", \"long\")\n",
    "city_df = city_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create city temperature dimension table\n",
    "monthly_city_temp_df = staging_temp_df.select(\"city_code\", \"year\", \"month\", \"avg_temperature\")\n",
    "monthly_city_temp_df = monthly_city_temp_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create dimension table for time\n",
    "time_df = staging_i94_df.withColumn(\"dayofweek\", dayofweek(\"date\"))\\\n",
    "                .withColumn(\"weekofyear\", weekofyear(\"date\"))\\\n",
    "                .withColumn(\"month\", month(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop duplicate\n",
    "time_df = time_df.select(\"date\", \"dayofweek\", \"weekofyear\", \"month\")\n",
    "time_df = time_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create immigration fact table\n",
    "immigration_df = staging_i94_df.select(\"id\", \"state_code\", \"city_code\", \"date\", \"count\")\n",
    "immigration_df = immigration_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...checking data quality is good...\n"
     ]
    }
   ],
   "source": [
    "# Perform quality checks here\n",
    "def check_table_existing(dataframe):\n",
    "    \"\"\"\n",
    "    To check if the dataframe exists or not\n",
    "    \"\"\"\n",
    "    if dataframe:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "        \n",
    "if check_table_existing(immigrant_df) & check_table_existing(city_df) & check_table_existing(monthly_city_temp_df) &\\\n",
    "    check_table_existing(time_df) & check_table_existing(immigration_df):\n",
    "    print(\"...checking data quality is good (all tables exist)...\")\n",
    "else:\n",
    "    print(\"...checking data quality has issues (some tables may not exist)...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Perform quality checks here\n",
    "def check_table_records(dataframe):\n",
    "    \"\"\"\n",
    "    To check if the dataframe is empty or not\n",
    "    \"\"\"\n",
    "    return dataframe.count() != 0 \n",
    "\n",
    "if check_table_records(immigrant_df) & check_table_records(city_df) & check_table_records(monthly_city_temp_df) &\\\n",
    "   check_table_records(time_df) & check_table_records(immigration_df):\n",
    "    print(\"...checking data quality is good (all tables contains records)...\")\n",
    "else:\n",
    "    print(\"...checking data quality has issues (some tables contain no records)...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Fact Table\n",
    "1. __immigration_df__ \n",
    "\n",
    "    - id: id\n",
    "    - state_code: state code of arrival city\n",
    "    - city_code: city port code of arrival city\n",
    "    - date: date of arrival\n",
    "    - count: count of immigrant's entries into the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Dimension Tables\n",
    "1. __immigrant_df__\n",
    "    - id: id of immigrant\n",
    "    - gender: gender of immigrant\n",
    "    - age: age of immigrant\n",
    "    - visa_type: immigrant's visa type\n",
    "2. __city_df__\n",
    "    - city_code: city port code\n",
    "    - state_code: state code of the city\n",
    "    - city_name: name of the city\n",
    "    - median_age: median age of the city\n",
    "    - pct_male_pop: city's male population in percentage\n",
    "    - pct_female_pop: city's female population in percentage\n",
    "    - pct_veterans: city's veteran population in percentage\n",
    "    - pct_foreign_born: city's foreign born population in percentage\n",
    "    - pct_native_american: city's native american population in percentage\n",
    "    - pct_asian: city's asian population in percentage\n",
    "    - pct_black: city's black population in percentage\n",
    "    - pct_hispanic_or_latino: city's hispanic or latino population in percentage\n",
    "    - pct_white: city's white population in percentage\n",
    "    - total_pop: city's total population\n",
    "    - lat: latitude of the city\n",
    "    - long: longitude of the city\n",
    "3. __monthly_city_temp_df__\n",
    "    - city_code: city port code\n",
    "    - year: year\n",
    "    - month: month \n",
    "    - avg_temperature: average temperature in city for given month\n",
    "4. __time_df__\n",
    "    - date: date\n",
    "    - dayofweek: day of the week\n",
    "    - weekofyear: week of year\n",
    "    - month: month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "    We chose Spark in this project because its capabilities in reading and processing massive amounts of data and its integration with a large number of other services like AWS. We also used Pandas to display dataset in a readable way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Propose how often the data should be updated and why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "    The data can be updated each month to capture a noticable change in data or upon the insertion of new elements to capture the change instantaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * __The data was increased by 100x__: We can move to cloud (AWS) and use powerful EC2 instances.\n",
    " * __The data populates a dashboard that must be updated on a daily basis by 7am every day__: We can use Ailflow for sceduling and monotoring tasks through a pipeline.\n",
    " * __The database needed to be accessed by 100+ people__: We can move to cloud (AWS) to manage all the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
